---
title: "MinIonTest"
author: "Emily Giroux"
date: "12/17/2021"
output: html_document
fontsize: 11pt
geometry: margin=1in
urlcolor: blue
header-includes: \usepackage{xcolor}
---

```{r, global_options, eval=TRUE, echo=FALSE, cache=TRUE}
library(knitr)
opts_chunk$set(tidy.opts=list(width.cutoff=80), tidy = TRUE, fig.align='center',
               cache=FALSE, collapse=TRUE, echo=FALSE, eval=FALSE, include=FALSE,
               message=FALSE, quietly=TRUE, results='hide', warn.conflicts=FALSE, 
               warning=FALSE)
```
Project Name Setting:
```{r}
analysis <- "AdvancedPreScreening"
```

Source our custom R scripts:    
For this we will use the rprojroot package to set the directory structures. This will help us when finding our files to source functions. We specify ours is an RStudio project. The root object contains a function that will help us locate our package R files regardless of our current working directory.
```{r sourcing_my_functions, echo=FALSE, eval=TRUE, include=FALSE, cache=TRUE}
library("rprojroot")
root <- rprojroot::is_rstudio_project

scriptsPath <- root$make_fix_file(".")("R")
scripts  <- dir(root$find_file("R", path = root$find_file()))
scriptsList <- paste(scriptsPath, scripts, sep = "//")
lapply(scriptsList, source)

scriptsPyPath <- root$make_fix_file(".")("pythonScripts")
scriptsPy <- dir(root$find_file(scriptsPyPath, path = root$find_file()))
scriptsPyList <- paste(scriptsPyPath, scriptsPy, sep = "//")

imagePath <- root$make_fix_file(".")(paste("r_environments", analysis, sep = "/"))
dir.create(imagePath, showWarnings = TRUE, recursive = TRUE)
images <- dir(root$find_file(imagePath, path = root$find_file())) # if there is already a data file in this directory if not running this for the first time
imagesList <- paste(imagePath, images, sep = "//")
load(paste(imagesList, sep = "/")) # you need to bget more specific if you have more than one image saved in this directory
```

Record the path to the environment images directory:
```{r importChptImage, echo=TRUE, eval=TRUE, include=FALSE, cache=TRUE}
library("rprojroot")
sharedPath <- root$make_fix_file(".")("PIRL_working_directory")
dir.create(sharedPath, showWarnings = TRUE, recursive = TRUE)
sharedPathDirs <- dir(root$find_file(sharedPath, path = root$find_file()))
sharedPathAn <- paste(sharedPath, analysis, sep = "/")
dir.create(sharedPathAn, showWarnings = TRUE, recursive = TRUE)

databasePath <- root$make_fix_file(".")(paste("Databases", analysis, sep = "/"))
dir.create(databasePath, showWarnings = TRUE, recursive = TRUE)
databasesPathDir <- dir(root$find_file(databasePath, path = root$find_file()))

refSeqDB <- paste(databasePath, "refSeq", sep = "/")
gbDB <- paste(databasePath, "genbank", sep = "/")
ensemblDB <- paste(databasePath, "ensembl", sep = "/")

subfolder_names <- c("/refSeq", "/genbank", "/ensembl")
for (j in 1:length(subfolder_names)){
  folder <- dir.create(paste0(databasePath, subfolder_names[j]), showWarnings = TRUE, recursive = FALSE)
}

# species within genus genomes 
generaGenomes <- paste(databasePath, "all_genomes_under_target_genera", sep = "/")
refSeqDBGenus <- paste(generaGenomes, "refSeq", sep = "/")
gbDBGenus <- paste(generaGenomes, "genbank", sep = "/")
ensemblDBGenus <- paste(generaGenomes, "ensembl", sep = "/")
for (j in 1:length(subfolder_names)){
  folder <- dir.create(paste0(generaGenomes, subfolder_names[j]), showWarnings = TRUE, recursive = TRUE)
}
```

```{r}
imageA <- "aps_test.RData" # should provide this variable in initial chunk where image directory is specified - but concern is that there may be the need to divide and create different files within the same anaylsis....
save.image(paste(imagePath, imageA, sep = "/")) # you need to bget more specific if you have more than one image saved in this directory
```

Reference genomes to obtain for target species, read csv:
```{r}
library("rprojroot")
library("data.table")
targetCsv <- "targetPathogens.csv"
targetCsvPath <- root$find_file(targetCsv)
targetMeta <- data.table::fread(targetCsvPath, sep = "auto", header = TRUE)
```

Need to obtain reference genomes for the target pathogens in the target Meta table:
```{r}
library("biomartr")
# set default timeout setting from 60s to at least 3000000 s before running any retrieval functions:
options(timeout = 30000000)
# List available database:
biomartr::listNCBIDatabases(db = "all")
# also try BarcodingR: https://besjournals.onlinelibrary.wiley.com/doi/full/10.1111/2041-210X.12682
```

RefSeq Genome Check:
```{r}
library("biomartr")
# set default timeout setting from 60s to at least 3000000 s before running any retrieval functions:
options(timeout = 30000000)
for(i in 1:nrow(targetMeta)){
  res <- biomartr::is.genome.available(db = "refseq", organism = targetMeta$SpeciesName[i])
  targetMeta$genRefSeq[i] <- res
  }
refSeqGens <- targetMeta[targetMeta$genRefSeq == "TRUE",]
for(i in 1:nrow(refSeqGens)){
  res <- biomartr::is.genome.available(db = "refseq", organism = refSeqGens$SpeciesName[i], details = TRUE)
  refSeqGens$assmblyAccn[i] <- res
}
save.image(paste(imagePath, imageA, sep = "/"))
```
RefSeq Genome Download of most recent version. Set up as a background job (Don't copy results - just double-check download folder has all genomes downloaded):
```{r}
options(timeout = 300000000)
library(biomartr)
for(i in 1:nrow(refSeqGens)){
  biomartr::getGenomeSet(db = "refseq", refSeqGens$SpeciesName[i], reference = FALSE, release = NULL, 
                         clean_retrieval = TRUE, gunzip = FALSE, update = FALSE, path = refSeqDB, 
                         assembly_type = "toplevel")
  biomartr::getAssemblyStats(db = "refseq", refSeqGens$SpeciesName[i], reference = FALSE, 
                             type = "download", 
                             #path = paste(refSeqDB, "/genomeassembly_stats", sep = ""))
                             path = refSeqDB)
  warnings()
}
```


Save env image:
```{r}
save.image(paste(imagePath, imageA, sep = "/"))
```

Ensembl Genome Check:
```{r}
for(i in 1:nrow(targetMeta)){
  res <- biomartr::is.genome.available(db = "ensembl", organism = targetMeta$SpeciesName[i])
  targetMeta$genEMBL[i] <- res
}
ensemblGens <- targetMeta[targetMeta$genEMBL == "TRUE",]
for(i in 1:nrow(ensemblGens)){
  res <- biomartr::is.genome.available(db = "ensembl", organism = ensemblGens$SpeciesName[i], details = TRUE)
  ensemblGens$assmblyAccn[i] <- res
}
```

Ensembl Genome Retrieval: (Run as background job)
```{r}
library(biomartr)
for(i in 1:nrow(ensemblGens)){
  biomartr::getGenomeSet(db = "ensembl", ensemblGens$SpeciesName[i], reference = FALSE, release = NULL,
                         clean_retrieval = TRUE, gunzip = FALSE, update = FALSE, path = ensemblDB,
                         assembly_type = "toplevel")
    biomartr::getAssemblyStats(db = "ensembl", ensemblGens$SpeciesName[i], reference = FALSE, 
                             type = "download", 
                             path = ensemblDB)
  warnings()
}
```

Save env image:
```{r}
save.image(paste(imagePath, imageA, sep = "/"))
```
    
GenBank Genome Check:
```{r}
for(i in 1:nrow(targetMeta)){
  res <- biomartr::is.genome.available(db = "genbank", organism = targetMeta$SpeciesName[i])
  targetMeta$genDB[i] <- res
}

gbGens <- targetMeta[targetMeta$genDB == "TRUE",]
for(i in 1:nrow(gbGens)){
  res <- biomartr::is.genome.available(db = "genbank", organism = gbGens$SpeciesName[i], details = TRUE)
  gbGens$assmblyAccn[i] <- res
}
```

GenBank Genome Retrieval: (Run as background job)
```{r}
library(biomartr)
for(i in 1:nrow(gbGens)){
  biomartr::getGenomeSet(db = "genbank", gbGens$SpeciesName[i], reference = FALSE, release = NULL,
                         clean_retrieval = TRUE, gunzip = FALSE, update = FALSE, path = gbDB,
                         assembly_type = "toplevel")
    biomartr::getAssemblyStats(db = "genbank", gbGens$SpeciesName[i], reference = FALSE, 
                             type = "download", 
                             path = gbDB)
  warnings()
}
```

Save env image:
```{r}
save.image(paste(imagePath, imageA, sep = "/"))
```

Species with no Genomes In GenBank and RefSeq:
```{r}
library("data.table")
otherDBs <- targetMeta[targetMeta$genDB == "FALSE" & targetMeta$genRefSeq == "FALSE" & targetMeta$genEMBL == "FALSE",]
```

Prepare for python function "nearest_genomes.py"
```{r}
library("data.table")
generaList <- unique(targetMeta$Genus)
nearestGensTbl <- as.data.table(generaList)
```

```{r}
library("reticulate")
nearestGenPyPath <- paste(scriptsPyPath, "nearest_genomes.py", sep = "/")
use_python(pythonPath)
source_python(nearestGenPyPath)

for(i in 1:nrow(nearestGensTbl)){
  accns_r <- nearest_genomes(nearestGensTbl$generaList[i])
  nearestGensTbl$accns[i] <- paste(accns_r, collapse = ", ")
}
```

Save env image:
```{r}
save.image(paste(imagePath, imageA, sep = "/"))
```

Ensembl Genome Retrieval: (Run as background job)
```{r}
library(biomartr)
for(i in 1:nrow(nearestGensTbl)){
  biomartr::getGenomeSet(db = "ensembl", nearestGensTbl$accns[i], reference = FALSE, release = NULL,
                         clean_retrieval = TRUE, gunzip = FALSE, update = FALSE, path = ensemblDBGenus,
                         assembly_type = "toplevel")
    biomartr::getAssemblyStats(db = "ensembl", nearestGensTbl$accns[i], reference = FALSE, 
                             type = "download", 
                             path = ensemblDBGenus)
  warnings()
}

for(i in 1:nrow(targetMeta)){
  res <- biomartr::is.genome.available(db = "genbank", organism = targetMeta$SpeciesName[i])
  targetMeta$genDB[i] <- res
}

gbGens <- targetMeta[targetMeta$genDB == "TRUE",]
for(i in 1:nrow(gbGens)){
  res <- biomartr::is.genome.available(db = "genbank", organism = gbGens$SpeciesName[i], details = TRUE)
  gbGens$assmblyAccn[i] <- res
}

library(biomartr)
for(i in 1:nrow(gbGens)){
  biomartr::getGenomeSet(db = "genbank", gbGens$SpeciesName[i], reference = FALSE, release = NULL,
                         clean_retrieval = TRUE, gunzip = FALSE, update = FALSE, path = gbDB,
                         assembly_type = "toplevel")
    biomartr::getAssemblyStats(db = "genbank", gbGens$SpeciesName[i], reference = FALSE, 
                             type = "download", 
                             path = gbDB)
  warnings()
}
```

Save env image:
```{r}
save.image(paste(imagePath, imageA, sep = "/"))
```


Obtain genomes from all species within a genus available from database:
```{r}
getKingdoms(db = "refseq")
getGroups(db = "refseq", kingdom = "fungi")
```



Using the new NCBI's datasets API to get the nearest available reference genomes for a given taxon or organism name.
Input: TAX_ID or Name
Output:
    1- The nearest organism with available reference genomes
    2- Accessions of the reference genomes
Requirements:
pip install --upgrade ncbi-datasets-pylib

*** over here!!!
Okay - so now need to figure out how to run and collect the output for this python code for each row in column of metadata... 22nov2022:
```{r}
organism_tax_or_name = targetMeta$Genus
```




Trying to find a way to get the genomes of all species withing a genus. Some ideas:     
- taxize github.com/ropensci/taxize, https:://reslp.github.io/blog/Download-Taxinfo-with-R/
- taxonkit - need to install in conda env, not an R package
- BarcodingR package - but need to see how useful this would be for us




```{r}
BiocManager::install("edgeR")
install.packages(c("taxize", "myTAI", "plyr", "usethis"))
library("taxize")
library("myTAI")
library("plyr")
taxize::use_entrez()
usethis::edit_r_environ()
ENTREZ_KEY='7f4be04d1855def2fe2aa44c9e2b94bc9a09'
myTAI::taxonomy(organism = targetMeta$Genus[1],
                db = "ncbi",
                output = "classification")




```


```{r}
rawPath <- "/isilon/cfia-ottawa-fallowfield/users/girouxeml/PIRL_working_directory/advancedPreScreening/data/raw/17Dec2021_HortonAllLongAmpRun2_cat.fastq"
rawSummary <- "/isilon/cfia-ottawa-fallowfield/users/girouxeml/PIRL_working_directory/advancedPreScreening/data/raw/sequencing_summary_17Dec2021_HortonAllLongAmpRun2_cat.txt"
```
 
### Basecalling    
    
### Error correction    
Vaser et al, 2017, "Fast and accurate de novo genome assembly from long uncorrected reads" 
- used RACON to skip error-correction and get consensus seqs with a SIMD-accelerated, partial-order alignment-based, stand-alone consensus module https://genome.cshlp.org/content/27/5/737
    
### consensus-generation   

"A workflow for accurate metabarcoding using nanopore MinION sequencing"
https://besjournals.onlinelibrary.wiley.com/doi/full/10.1111/2041-210X.13561

"build error-corrected consensus sequences"
Python pipeline "ASHURE" and "OPTICS density-based clustering"for:
- data processing
consensus building
clustering - use reference genomes, primer indices marking each sample, or spatially-related sequence information
taxonomic assignment

"ASHURE" compared to C3POa workflow for consensus error correction of nanopore reads

see what our median accuracies are
see how many successfully identified species can be retrieved from the mock sample


https://www.sciencedirect.com/science/article/pii/S1872497321000326
clustering method "NGSpeciesID" tp generate accurate consensus sequence for species identification
- consensus seqs constructed from a multiple seq alignment software:
- seq reads are clustered based on seq homology with the aim of generating a single consensus seq for every source of input DNA
- for species id, this means that one consensus seq should be generated per distinct taxon present within a sample
- then sompared against a reference database to identify the species




really cool method to increase accuracy is RCA - rolling circle amplification so that replicated sequneces can be used to build concensus sequences with an accuracy of up to 99.5%

metabarcoding and nanopore sequencing could allow researchers wto generate barcode sequence data for community samples in the field without the need to transport or ship samples to a lab.

gff <- read.table(file = gffPathPr, 
                  sep = "\t", header = F, quote = "", comment.char="#", fill = T)
                  
metadata <-  read.table(paste(sharedPathAn, metadataFileAlternate, sep = ""),
                        sep = ",", header = TRUE, comment.char = "", quote = "", as.is = TRUE)
                        
                        
for(i in 1:nrow(metadataAssembly)){
    kmerdatTmp <- fread(metadataAssembly$kmerGenieDatPath[i], sep = "auto", header = TRUE)
    setkey(kmerdatTmp, genomic.kmers)
    key(kmerdatTmp)
    maxGenomicKmers <- max(kmerdatTmp$genomic.kmers)
    metadataAssembly$BestKmerGenie[i] <- kmerdatTmp[.(maxGenomicKmers), .(k)]
}



i <- 1
for(i in 1:length(listABySS_fac_res)){
    test[[i]] <- fread(listABySS_fac_res[i], sep = "auto", header = TRUE)
    test[[i]]$ABySSfastq <- basename(test[[i]]$name)
    print(nrow(test[[i]]))
}

blastnTmp <- fread(metadataAssemblySubTemp$LawiiMitoBlastPath[i], sep = "auto", header = FALSE)

cazyLawiAll <- fread(metadataAssembly$domtbloutPath[7], sep = "auto", header = TRUE, fill=TRUE)

cazy analysis RstudioScript-June2017_LachnellulaSpp_assemblies.Rmd line 2055


library(reshape2)
library(data.table)
dbCANList <- metadataAssembly$ParsedmtblPath
i <- 1
test <- lapply(dbCANList, fread, sep = "auto", header = FALSE)
namesCols <- c("family.hmm", "hmm.length", "query.id", "query.length", "e.val",
               "hmm.start", "hmm.end", "query.start", "query.end", "coverage")
for(i in 1:length(test)){
  setnames(test[[i]], 1:10, namesCols)
}

dbCAN_tempFile <- fread(paste(sharedPathAn, "dbCAN_CAZySubset_AllRefs.csv", sep = ""),
                        sep="auto", header = TRUE)
                        
library(data.table)
metadataAssemblies <- fread(paste(sharedPathAn, "Lachnellula_genomes_MetadataAssembly.csv", sep = ""),
                            sep = "auto", header = TRUE)
metadataAssemblies[, V1:=NULL]




